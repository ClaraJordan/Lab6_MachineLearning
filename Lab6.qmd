---
title: "Lab6.qmd"
author: "Clara Jordan"
format:
  html:
    self-contained: true
editor: visual
execute:
  echo: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lab Set Up

## Downloading necessary tools

```{r}
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
library(xgboost)
library(ggpubr)
library(ggplot2)
library(dplyr)
```

## Data & Documentation Download

```{r}
root  <- 'https://gdex.ucar.edu/dataset/camels/file'

download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 
              'data/camels_attributes_v2.0.pdf')
```

## Getting Basin Characteristics

```{r}
# A. Lets create a vector storing the data types/file names we want to download:

types <- c("clim", "geol", "soil", "topo", "vege", "hydro")

# B. Using glue, we can construct the needed URLs and file names for the data we want to download:

    # Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
    # where we want to download the data ...
local_files   <- glue('data/camels_{types}.txt')

# C. Now we can download the data: walk2 comes from the purrr package and is used to apply a function to multiple arguments in parallel (much like map2 works over paired lists). Here, we are asking walk2 to pass the first element of remote_files and the first element of local_files to the download.file function to download the data, and setting quiet = TRUE to suppress output. The process is then iterated for the second element of each vector, and so on.

walk2(remote_files, local_files, download.file, quiet = TRUE)

# D. Once downloaded, the data can be read it into R using readr::read_delim(), again instead of applying this to each file individually, we can use map to apply the function to each element of the local_files list.

    # Read and merge data
camels <- map(local_files, read_delim, show_col_types = FALSE) 

# E. This gives us a list of data.frames, one for each file that we want to merge into a single table. So far in class we have focused on *_join functions to merge data based on a primary and foreign key relationship.

camels <- power_full_join(camels ,by = 'gauge_id')

```

# Question 1: Exploratory Data Analysis

## Making a Map of The Sites

```{r}
ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = q_mean)) +
  scale_color_gradient(low = "pink", high = "dodgerblue") +
  ggthemes::theme_map()
```

## What "zero_q_freq" Represents:

"zero_q_freq" is the frequency of days with Q = 0 mm/day, reported as a percentage. Q indicates daily discharge.

# Question 2: Model Preparation

## Making Two Maps of the Sites

```{r}
p1 <- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = aridity)) +
  scale_color_gradient(low = "palegreen", high = "brown") +
  labs(x = "Longitude", y = "Latitude", title = "Aridity Gradient Across the United States") + 
  ggthemes::theme_map()

p2 <- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = p_mean)) +
  scale_color_gradient(low = "lightblue", high = "purple") +
  labs(x = "Longitude", y = "Latitude", title = "Mean Daily Precipitation Across the United States") + 
  ggthemes::theme_map()

ggarrange(p1, p2, ncol = 2)
```

## Model Preparation

```{r}
# Make sure there is not significant correlation between these variables.
camels |> 
  select(aridity, p_mean, q_mean) |> 
  drop_na() |> 
  cor()
```

## Visual EDA

```{r}
# A. Lets start by looking that the 3 dimensions (variables) of this data. We’ll start with a XY plot of aridity and rainfall. We are going to use the scale_color_viridis_c() function to color the points by the q_mean column. This scale functions maps the color of the points to the values in the q_mean column along the viridis continuous (c) palette. Because a scale_color_* function is applied, it maps to the known color aesthetic in the plot.

    # Create a scatter plot of aridity vs rainfall
ggplot(camels, aes(x = aridity, y = p_mean)) +
     # Add points colored by mean flow
  geom_point(aes(color = q_mean)) +
     # Add a linear regression line
  geom_smooth(method = "lm", color = "red", linetype = 2) +
     # Apply the viridis color scale
  scale_color_viridis_c() +
      # Add a title, axis labels, and theme (w/ legend on the bottom)
  theme_linedraw() + 
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")

    # To test a transformation, we can log transform the x and y axes using the     
    # scale_x_log10() and scale_y_log10() functions:
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  scale_color_viridis_c() +
  # Apply log transformations to the x and y axes
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")

    # To address this, we can visualize how a log transform may benifit the q_mean data as     # well. Since the data is represented by color, rather then an axis, we can use the       # trans (transform) argument in the scale_color_viridis_c() function to log transform     # the color scale.
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  # Apply a log transformation to the color scale
  scale_color_viridis_c(trans = "log") +
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom",
        # Expand the legend width ...
        legend.key.width = unit(2.5, "cm"),
        legend.key.height = unit(.5, "cm")) + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow") 
```

## Model Building

### Lets start by splitting the data

First, we set a seed for reproducabilty, then transform the q_mean column to a log scale. Remember it is error prone to apply transformations to the outcome variable within a recipe. So, we’ll do it a prioi.

Once set, we can split the data into a training and testing set. We are going to use 80% of the data for training and 20% for testing with no stratification.

Additionally, we are going to create a 10-fold cross validation dataset to help us evaluate multi-model setups.

```{r}
set.seed(123)
    # Bad form to perform simple transformations on the outcome variable within a 
    # recipe. So, we'll do it here.
camels <- camels |> 
  mutate(logQmean = log(q_mean))

    # Generate the split
camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)
```

### Preprocessor: Recipe

```{r}
    # Create a recipe to preprocess the data
rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
      # Log transform the predictor variables (aridity and p_mean)
  step_log(all_predictors()) %>%
      # Add an interaction term between aridity and p_mean
  step_interact(terms = ~ aridity:p_mean) |> 
      # Drop any rows with missing values in the pred
  step_naomit(all_predictors(), all_outcomes())
```

### Naive base lm approach

```{r}
    # Prepare the data
baked_data <- prep(rec, camels_train) |> 
  bake(new_data = NULL)

    # Interaction with lm
    #  Base lm sets interaction terms with the * symbol
lm_base <- lm(logQmean ~ aridity * p_mean, data = baked_data)
summary(lm_base)
```

### Check the recipe

```{r}
# Sanity Interaction term from recipe ... these should be equal!!
summary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))
```

### Wrong Version 1: Augment

```{r}
nrow(camels_test)

nrow(camels_train)

# broom::augment(lm_base, data = camels_test)

    # I got the error but am commenting out my code so I can render my document. 
```

### Wrong Version 2: Predict

```{r}
camels_test$p2 = predict(lm_base, newdata = camels_test)

    ## Scales way off!
ggplot(camels_test, aes(x = p2, y = logQmean)) + 
  geom_point() + 
      # Linear fit line, no error bands
  geom_smooth(method = "lm", se = FALSE, size =1) +
      # 1:1 line
  geom_abline(color = "red", size = 1) + 
  labs(title = "Linear Model Using `predict()`",
       x = "Predicted Log Mean Flow",
       y = "Observed Log Mean Flow") + 
  theme_linedraw()
```

### Correct Version: Prep -\> Bake -\> Predict!

```{r}
test_data <-  bake(prep(rec), new_data = camels_test)
test_data$lm_pred <- predict(lm_base, newdata = test_data)
```

## Model Evaluation: Statistical and Visual

Now that we have the predicted values, we can evaluate the model using the metrics function from the yardstick package. This function calculates common regression metrics such as RMSE, R-squared, and MAE between the observed and predicted values.

```{r}
metrics(test_data, truth = logQmean, estimate = lm_pred)
```

### Creating a Linear Model

```{r}
ggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +
  # Apply a gradient color scale
  scale_color_gradient2(low = "brown", mid = "orange", high = "darkgreen") +
  geom_point() +
  geom_abline(linetype = 2) +
  theme_linedraw() + 
  labs(title = "Linear Model: Observed vs Predicted",
       x = "Observed Log Mean Flow",
       y = "Predicted Log Mean Flow",
       color = "Aridity")
```

### Using a workflow instead

```{r}
# Define model
lm_model <- linear_reg() %>%
  # define the engine
  set_engine("lm") %>%
  # define the mode
  set_mode("regression")

# Instantiate a workflow ...
lm_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(lm_model) %>%
  # Fit the model to the training data
  fit(data = camels_train) 

# Extract the model coefficients from the workflow
summary(extract_fit_engine(lm_wf))$coefficients
```

Lets ensure we replicated the results from the lm_base model. How do they look to you?

```{r}
# From the base implementation
summary(lm_base)$coefficients
```

### Making Predictions

Now that lm_wf is a workflow, data is not embedded in the model, we can use augment with the new_data argument to make predictions on the test data.
```{r}
lm_data <- augment(lm_wf, new_data = camels_test)
dim(lm_data)
```

## Model Evaluation: Statistical and Visual

As with EDA, applying for graphical and statistical evaluation of the model is a key Here, we use the metrics function to extract the default metrics (rmse, rsq, mae) between the observed and predicted mean streamflow values.

We then create a scatter plot of the observed vs predicted values, colored by aridity, to visualize the model performance.
```{r}
metrics(lm_data, truth = logQmean, estimate = .pred)

ggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

### Switch it Up! 
```{r}
library(baguette)
rf_model <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(rf_model) %>%
  # Fit the model
  fit(data = camels_train) 
```

### Predictions
```{r}
rf_data <- augment(rf_wf, new_data = camels_test)
dim(rf_data)
```

## Model Evaluation: Statistical and Visual

Evaluate the model using the metrics function and create a scatter plot of the observed vs predicted values, colored by aridity.
```{r}
metrics(rf_data, truth = logQmean, estimate = .pred)

ggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

### A Workflowset Approach

workflow_set is a powerful tool for comparing multiple models on the same data. It allows you to define a set of workflows, fit them to the same data, and evaluate their performance using a common metric. Here, we are going to create a workflow_set object with the linear regression and random forest models, fit them to the training data, and compare their performance using the autoplot and rank_results functions.
```{r}
wf <- workflow_set(list(rec), list(lm_model, rf_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv) 

autoplot(wf)

rank_results(wf, rank_metric = "rsq", select_best = TRUE)
```

# Question 3: Your Turn! (20 points)

## Build a xgboost (engine) regression (mode) model using boost_tree
```{r}
xgBoost_model <- boost_tree(mode = "regression",
                            trees = 1000) |>
  set_engine('xgboost')
```

## Build a neural network model using the nnet engine from the baguette package using the bag_mlp function
```{r}
NeuralNet_Model <- bag_mlp(mode = "regression") |>
  set_engine('nnet')
```

## Add this to the above workflow
```{r}
xgbm_wf <- workflow() |>
  add_recipe(rec) |>
  add_model(xgBoost_model) |>
  fit(data = camels_train) |>
  augment(camels_train)
  
NeuralNet_Model_wf <- workflow() |>
  add_recipe(rec) |>
  add_model(xgBoost_model) |>
  fit(data = camels_train) |>
  augment(camels_train)
```

## Evaluate the model and compare it to the linear and random forest models
```{r}
metrics(xgbm_wf, truth = logQmean, estimate = .pred)
metrics(NeuralNet_Model_wf, truth = logQmean, estimate = .pred)

ggplot(xgbm_wf, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()

ggplot(NeuralNet_Model_wf, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()

autoplot(wf)

# Comparison of the boosted tree, neural network, linear regression, and random forest models: 

    # ANSWER: The boosted tree and neural network model returned the same results, whereas the results between the linear regression model and random forest model were slightly different. I would move forward with the boosted tree and neural network model because the results are right on the 1:1 line and the metrics have significance. 
```
# Question 4: Build Your Own

## Data Splitting 

### Set a Seed
```{r}
set.seed(123456)
```

### Create an initial split with 75% used for training and 25% for testing
```{r}
resample_split <- initial_split(camels, prop = 0.75)
```

### Extract your training and testing sets
```{r}
train_camels <- training(resample_split)
glimpse(train_camels)

test_camels <- testing(resample_split)
glimpse(test_camels)
```

### Build a 10-fold CV dataset as well
```{r}
cv_folds <- vfold_cv(train_camels, v = 10)

cv_folds
```

## Recipe

### Define a formula you want to use to predict logQmean
```{r}
formula <- logQmean ~ p_mean + aridity + high_prec_dur
```

### Describe in words why you are choosing the formula you are. Consult the downloaded PDF for the data to help you make this decision.

I chose the formula I did with the predictor variables of p_mean, aridity, and logQmean because I think these are all factors that will influence mean daily discharge. Precipitation will influence discharge by inputting water into the system; aridity describes how dry an environment is so more arid environments will probably have lower logQmean; I think that high_prec_dur will correlate with logQmean because more high precipitation events will lead to more mean daily discharge. 

### Build a recipe that you feel handles the predictors chosen well
```{r}
train_camels <- na.omit(train_camels)

    # Create a recipe to preprocess the data
rec <-  recipe(logQmean ~ p_mean + aridity + high_prec_dur, data = train_camels) %>%
      # Log transform the predictor variables (aridity and p_mean)
  step_log(all_predictors()) %>%
      # Add an interaction term between aridity and p_mean
      # step_interact(terms = ~ aridity:p_mean) |> 
      # Drop any rows with missing values in the pred
  step_naomit(all_predictors(), all_outcomes()) %>%
  step_zv(all_predictors())

    # Prep and bake data
rec_prep <- prep(rec, training = train_camels)
baked_data <- bake(rec_prep, new_data = NULL)

    # Make sure my data doesn't have NA or inf values. 
sum(is.na(baked_data)) # Should return 0
sum(is.infinite(as.matrix(baked_data))) # Should return 0
```

## Define 3 Models

### Define a random forest model using the rand_forest function & Set the engine to ranger and the mode to regression
```{r}
Q4_rf_model <- rand_forest() %>%
  set_engine("ranger") %>%
  set_mode("regression")
```

### Define two other models of your choice
```{r}
Q4_lm_model <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

Q4_gbm_model <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("regression")
```

## Workflow Set

### Create a workflow object, add the recipe, and add the models. Additionally, fit the models to the resamples. 
```{r}
    # Define workflows 
Q4_rf_wf <- workflow() |>
  add_recipe(rec) |>
  add_model(Q4_rf_model)

Q4_lm_wf <- workflow() |>
  add_recipe(rec) |>
  add_model(Q4_lm_model)

Q4_gbm_wf <- workflow() |>
  add_recipe(rec) |>
  add_model(Q4_gbm_model)

    # Use fit_resamples directly on the workflows
rf_results <- fit_resamples(Q4_rf_wf, resamples = cv_folds)
lm_results <- fit_resamples(Q4_lm_wf, resamples = cv_folds)
gbm_results <- fit_resamples(Q4_gbm_wf, resamples = cv_folds)
```

## Evaluation 

### Use autoplot and rank_results to compare the models.
```{r}
wf <- workflow_set(list(rec), list(Q4_rf_model, Q4_lm_model, Q4_gbm_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv) 

autoplot(wf)

rank_results(wf, rank_metric = "rsq", select_best = TRUE)
```

### Describe what model you think is best and why!

I think that the random forest is the best model because it has the best ranked metrics for both RMSE and RSQ, indicating high coincidence in our model with the data. 

## Extact and Evaluate

### Build a workflow (not workflow set) with your favorite model, recipe, and training data. Use fit to fit all training data to the model.
```{r}
final_workflow <- workflow() |>
  add_recipe(rec) |>
  add_model(Q4_rf_model) |>
  fit(data = train_camels)
```

### Use augment to make predictions on the test data
```{r}
final_workflow_data <- augment(final_workflow, new_data = camels_test)
```

### Create a plot of the observed vs predicted values with clear title, axis labels, and a compelling color scale
```{r}
ggplot(final_workflow_data, aes(x = .pred, y = logQmean, colour = logQmean)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Observed vs Predicted Values",
       x = "Predicted logQmean",
       y = "Observed logQmean") +
  scale_color_viridis_c()
```

### Describe what you think of the results!

The results seem to be fairly accurate! The plotted points of observed versus predicted logQmean values are clustered along the 1:1 line, indicating strong accuracy of the model's predictions. It's awesome that I created a model that is able to predict logQmean based on the predictors I chose! 

